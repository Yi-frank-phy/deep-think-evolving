"""
WriterAgent - æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆå™¨

åœ¨è¿›åŒ–è¿‡ç¨‹æ”¶æ•›åï¼Œå°†æ‰€æœ‰ç ”ç©¶å‘ç°ç»¼åˆæˆä¸€ä»½ç»“æ„åŒ–çš„æœ€ç»ˆæŠ¥å‘Š/å›ç­”ã€‚

å‚è€ƒè®¾è®¡: LangChain Open Deep Research çš„ final_report_generation
"""

import os
from typing import List, Optional

from langchain_core.prompts import ChatPromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI

from src.core.state import DeepThinkState, StrategyNode


# System prompt for WriterAgent
WRITER_SYSTEM_PROMPT = """\
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç ”ç©¶æŠ¥å‘Šæ’°å†™è€… (Writer Agent)ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†è¿›åŒ–ç ”ç©¶è¿‡ç¨‹çš„æˆæœç»¼åˆæˆä¸€ä»½æ¸…æ™°ã€ç»“æ„åŒ–çš„æœ€ç»ˆæŠ¥å‘Šã€‚

## ä½ çš„èŒè´£

1. **ç»¼åˆåˆ†æ**ï¼šæ•´åˆæ‰€æœ‰æ”¶æ•›åçš„ç­–ç•¥ï¼Œæå–æ ¸å¿ƒæ´è§
2. **ç»“æ„åŒ–è¾“å‡º**ï¼šç”Ÿæˆæ˜“äºé˜…è¯»çš„æŠ¥å‘Šï¼ŒåŒ…å«é—®é¢˜æ€»ç»“ã€ä¸»è¦å‘ç°ã€æ¨èæ–¹æ¡ˆ
3. **å¼•ç”¨æ¥æº**ï¼šå¦‚æœ‰æœç´¢ç»“æœæˆ–å¤–éƒ¨ä¿¡æ¯ï¼Œæ­£ç¡®å¼•ç”¨
4. **è¯­è¨€é€‚é…**ï¼šä½¿ç”¨ä¸ç”¨æˆ·é—®é¢˜ç›¸åŒçš„è¯­è¨€æ’°å†™æŠ¥å‘Š

## æŠ¥å‘Šé£æ ¼

- ä½¿ç”¨ Markdown æ ¼å¼
- ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€
- é‡ç‚¹çªå‡ºå…³é”®å‘ç°
- æä¾›å¯æ“ä½œçš„å»ºè®®
"""


REPORT_GENERATION_PROMPT = """\
åŸºäºä»¥ä¸‹è¿›åŒ–ç ”ç©¶è¿‡ç¨‹çš„æˆæœï¼Œç”Ÿæˆä¸€ä»½å…¨é¢ã€ç»“æ„åŒ–çš„æœ€ç»ˆæŠ¥å‘Šï¼š

---

## åŸå§‹é—®é¢˜

{problem_state}

---

## ç ”ç©¶èƒŒæ™¯

{research_context}

---

## ç­–ç•¥åˆ†æç»“æœï¼ˆæŒ‰è¯„åˆ†ä»é«˜åˆ°ä½ï¼‰

{strategies_summary}

---

## è¿­ä»£ç»Ÿè®¡

- æ€»è¿­ä»£æ¬¡æ•°: {iteration_count}
- æœ€ç»ˆç©ºé—´ç†µ: {final_entropy:.4f}
- ç­–ç•¥æ€»æ•°: {total_strategies}ï¼ˆæ´»è·ƒ: {active_count}ï¼Œå·²æ‰©å±•: {expanded_count}ï¼‰

---

## æŠ¥å‘Šç”Ÿæˆä»»åŠ¡

è¯·ç”Ÿæˆä¸€ä»½è¯¦ç»†çš„ç ”ç©¶æŠ¥å‘Šï¼ŒåŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š

### 1. é—®é¢˜æ‘˜è¦
ç®€æ´é‡è¿°é—®é¢˜æ ¸å¿ƒï¼Œæ˜ç¡®ç ”ç©¶ç›®æ ‡ã€‚

### 2. ä¸»è¦å‘ç°
- æ’åæœ€é«˜çš„ç­–ç•¥åŠå…¶æ ¸å¿ƒæ€è·¯
- å…³é”®æ´è§å’Œçªç ´ç‚¹
- ä¸åŒç­–ç•¥ä¹‹é—´çš„å…±æ€§å’Œå·®å¼‚

### 3. å¯¹æ¯”åˆ†æ
åˆ†æå„ç­–ç•¥çš„ä¼˜åŠ£åŠ¿ï¼Œè§£é‡Šä¸ºä½•æŸäº›ç­–ç•¥è¡¨ç°æ›´å¥½ã€‚

### 4. æ¨èæ–¹æ¡ˆ
åŸºäºåˆ†æç»“æœï¼Œç»™å‡ºå…·ä½“å¯æ“ä½œçš„å»ºè®®ã€‚

### 5. æ¥æºå¼•ç”¨ï¼ˆå¦‚æœ‰ï¼‰
å¦‚æœç ”ç©¶è¿‡ç¨‹ä¸­ä½¿ç”¨äº†å¤–éƒ¨æœç´¢ç»“æœï¼Œåˆ—å‡ºå‚è€ƒé“¾æ¥ã€‚

---

**è¯­è¨€è¦æ±‚**ï¼šè¯·ä½¿ç”¨ä¸"åŸå§‹é—®é¢˜"ç›¸åŒçš„è¯­è¨€æ’°å†™æ•´ä»½æŠ¥å‘Šã€‚
"""


def _format_strategies_summary(strategies: List[StrategyNode], top_n: int = 5) -> str:
    """Format top strategies into a readable summary."""
    if not strategies:
        return "ï¼ˆæ— ç­–ç•¥æ•°æ®ï¼‰"
    
    # Sort by score (descending)
    sorted_strategies = sorted(
        strategies,
        key=lambda s: s.get("score", 0),
        reverse=True
    )
    
    lines = []
    for i, s in enumerate(sorted_strategies[:top_n]):
        status = s.get("status", "unknown")
        score = s.get("score", 0)
        name = s.get("name", "æœªå‘½åç­–ç•¥")
        rationale = s.get("rationale", "æ— æè¿°")
        assumption = s.get("assumption", "æ— å‡è®¾")
        
        # Get last few trajectory entries
        trajectory = s.get("trajectory", [])
        recent_trajectory = trajectory[-3:] if trajectory else []
        trajectory_str = "\n".join([f"      - {t}" for t in recent_trajectory]) if recent_trajectory else "      ï¼ˆæ— æ‰§è¡Œè®°å½•ï¼‰"
        
        lines.append(f"""
### {i+1}. {name}
- **çŠ¶æ€**: {status}
- **è¯„åˆ†**: {score:.3f}
- **æ ¸å¿ƒæ€è·¯**: {rationale[:200]}...
- **å…³é”®å‡è®¾**: {assumption[:150]}...
- **æœ€è¿‘æ‰§è¡Œ**:
{trajectory_str}
""")
    
    # Add summary of remaining strategies if any
    remaining = len(sorted_strategies) - top_n
    if remaining > 0:
        lines.append(f"\n*ï¼ˆå¦æœ‰ {remaining} æ¡ç­–ç•¥æœªè¯¦ç»†å±•ç¤ºï¼‰*")
    
    return "\n".join(lines)


def writer_node(state: DeepThinkState) -> DeepThinkState:
    """
    WriterAgent: å°†æ‰€æœ‰æ”¶æ•›çš„ç­–ç•¥ç»¼åˆæˆæœ€ç»ˆæŠ¥å‘Šã€‚
    
    åœ¨ Evolution åˆ¤å®šæ”¶æ•›åè°ƒç”¨ï¼Œç”Ÿæˆ final_report å­—æ®µã€‚
    
    åŠŸèƒ½ï¼š
    1. æ”¶é›†æ‰€æœ‰ç­–ç•¥å’Œç ”ç©¶ä¸Šä¸‹æ–‡
    2. è°ƒç”¨ LLM ç”Ÿæˆç»“æ„åŒ–æŠ¥å‘Š
    3. æ”¯æŒå¤šè¯­è¨€ï¼ˆè·Ÿéšç”¨æˆ·é—®é¢˜è¯­è¨€ï¼‰
    """
    print("\n[Writer] Generating final report...")
    
    api_key = os.environ.get("GEMINI_API_KEY")
    use_mock = os.environ.get("USE_MOCK_AGENTS", "false").lower() == "true" or not api_key
    
    if not api_key and not use_mock:
        print("[Writer] Error: GEMINI_API_KEY not set. Generating placeholder report.")
        return {
            **state,
            "final_report": "âš ï¸ æ— æ³•ç”ŸæˆæŠ¥å‘Šï¼šæœªé…ç½® GEMINI_API_KEY",
            "history": state.get("history", []) + ["[Writer] æŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼ˆæ—  API Keyï¼‰"]
        }
    
    # Collect data from state
    problem_state = state.get("problem_state", "ï¼ˆæ— é—®é¢˜æè¿°ï¼‰")
    research_context = state.get("research_context") or "ï¼ˆæ— ç ”ç©¶èƒŒæ™¯èµ„æ–™ï¼‰"
    strategies = state.get("strategies", [])
    iteration_count = state.get("iteration_count", 0)
    spatial_entropy = state.get("spatial_entropy", 0.0)
    
    # Calculate strategy statistics
    active_count = len([s for s in strategies if s.get("status") == "active"])
    expanded_count = len([s for s in strategies if s.get("status") == "expanded"])
    total_strategies = len(strategies)
    
    # Format strategies summary
    strategies_summary = _format_strategies_summary(strategies, top_n=5)
    
    if use_mock:
        print("[Writer] Running in MOCK MODE.")
        # Generate mock report
        mock_report = f"""# ğŸ“ ç ”ç©¶æŠ¥å‘Š (Mock)

## é—®é¢˜æ‘˜è¦
{problem_state[:200]}...

## ä¸»è¦å‘ç°
- å…±ç”Ÿæˆ {total_strategies} æ¡ç­–ç•¥
- ç»è¿‡ {iteration_count} è½®è¿­ä»£æ”¶æ•›
- æœ€ç»ˆç©ºé—´ç†µ: {spatial_entropy:.4f}

## æ¨èæ–¹æ¡ˆ
åŸºäº Mock æ¨¡å¼ï¼Œæ— æ³•ç”ŸæˆçœŸå®åˆ†æã€‚è¯·é…ç½® GEMINI_API_KEY è·å–å®Œæ•´æŠ¥å‘Šã€‚

---
*æ­¤æŠ¥å‘Šç”± Mock æ¨¡å¼ç”Ÿæˆ*
"""
        print("[Writer] Mock report generated.")
        return {
            **state,
            "final_report": mock_report,
            "history": state.get("history", []) + ["[Writer] Mock æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ"]
        }
    
    # Initialize LLM
    model_name = os.environ.get(
        "GEMINI_MODEL_WRITER",
        os.environ.get("GEMINI_MODEL", "gemini-2.0-flash")
    )
    print(f"[Writer] Using model: {model_name}")
    
    try:
        llm = ChatGoogleGenerativeAI(
            model=model_name,
            google_api_key=api_key,
            temperature=0.7,  # Slightly creative for report writing
        )
        
        # Build prompt
        prompt = ChatPromptTemplate.from_messages([
            ("system", WRITER_SYSTEM_PROMPT),
            ("human", REPORT_GENERATION_PROMPT)
        ])
        
        messages = prompt.format_messages(
            problem_state=problem_state,
            research_context=research_context[:2000],  # Truncate if too long
            strategies_summary=strategies_summary,
            iteration_count=iteration_count,
            final_entropy=spatial_entropy,
            total_strategies=total_strategies,
            active_count=active_count,
            expanded_count=expanded_count
        )
        
        # Generate report
        response = llm.invoke(messages)
        final_report = response.content
        
        print(f"[Writer] Report generated ({len(final_report)} chars)")
        
        return {
            **state,
            "final_report": final_report,
            "history": state.get("history", []) + [
                f"[Writer] æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ ({len(final_report)} å­—ç¬¦)"
            ]
        }
        
    except Exception as e:
        error_msg = f"âš ï¸ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}"
        print(f"[Writer] Error: {e}")
        import traceback
        traceback.print_exc()
        
        return {
            **state,
            "final_report": error_msg,
            "history": state.get("history", []) + [f"[Writer] æŠ¥å‘Šç”Ÿæˆé”™è¯¯: {e}"]
        }
